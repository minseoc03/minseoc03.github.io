---
layout: single
title:  "CNN Feature Extraction"
date:   2024-05-09 20:10:54 
categories: [ml, dl_theory]
author_profile: false
sidebar:
  nav: "ml"
---
## 8-2. CNN의 특징 추출 방법

### Convolution의 특징 추출

![image 11.png](/assets/images/dl-theory/image%2011.png)

- 각 필터들이 왼쪽 위부터 오른쪽 아래 순서로 이미지를 스캔하며 내적을 구한다.
    - 내적은 닮은 정도를 나타내기에 필터의 패턴과 비슷할 수록 값이 크게 나올 것이다.
- 필터가 스캔하면서 나온 내적 값들은 위치 정보를 담기 위해 그림의 우측과 같은 형태로 적어준다.
    - 스캔한 방향을 고려한다.
- 위와 같이 세로 패턴을 담고 있는 필터는 세로 패턴이 나온 위치의 내적이 큰 것을 볼 수가 있다.
- 그와 달리 가로 패턴을 담고 있는 필터는 입력 이미지에 가로 패턴이 존재하지 않으므로 모든 값이 0이 나온다.

![image.png](/assets/images/dl-theory/image%201%209.png)

- 반대되는 예시로 보자면 입력 이미지에 가로 패턴이 들어가고 세로 패턴이 없어지자, 세로 필터의 출력 값은 모두 0이 되었고 가로 필터는 가로 패턴이 있는 부분에 내적 값이 출력 되었다.

- 크게 안와닿을까봐 실제 이미지 데이터를 가지고 필터링을 진행해보았다.

- 자세히 보면 가로 edge와 세로 edge가 추출된 것을 볼수 가 있다.

![image.png](/assets/images/dl-theory/image%202%205.png)

### Feature Map

- 컨볼루션 연산을 한번만 진행하는 것이 아니라 여러 특징들을 추출하기 위해 여러 개의 필터를 가지고 여러 개의 필터링을 진행할 것이다.
- 그렇다면 여러 개의 필터링 결과를 위치 정보를 유지하며 결과를 사용하려면 어떻게 해야할까?

![image.png](/assets/images/dl-theory/image%203%203.png)

- 위와 같이 RGB채널 마냥 쌓아버리면 된다.
- 쌓여진 필터링 결과물들은 Feature Map이라고 부른다.
- 그리고 커널 안에 들어가는 모든 값들은 학습 파라미터이다.

### Conv. Layer vs. FC Layer

- FC와 다르게 주변만 연결을 하기 때문에 위치 정보를 잃지 않는다.
- 가중치가 재사용이 된다.
    - 커널이 이미지를 위에서부터 아래까지 쭉 긁으면서 스캔을 하기 때문에 특정 특징이 어디에 있는 인식을 하게 된다.
- 여러 종류의 필터로 여러 종류의 특징을 추출할 수 있다.
- 각 필터가 어떤 특징을 추출하는지 머신이 학습을 한다.
- 예를 들어 Conv. layer로 FC layer를 표현해보자.
    - 100x100 입력 이미지에 , 커널 사이즈 100x100, 커널 종류 10개 사용하는 합성곱은 10000→10 으로 가는 FC 레이어와 다를게 없다.