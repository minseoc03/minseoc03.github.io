---
layout: single
title:  "CNN Summary"
date:   2024-05-13 21:10:54 
categories: [ml, dl_theory]
author_profile: false
sidebar:
  nav: "ml"
---
# 8-7. CNN 요약

### 합성곱의 중요성

- 아주 적은 수의 가중치로 위치별 특징을 파악 가능
- 사전 입력에는 반드시 특정 패턴이 있고 합성곱은 위치별 패턴을 찾는 연산이다.
    - 신경망을 잘 끊어서 특징을 잘 파악한다
- CNN을 통과하면서 그 패턴들이 곱해지며 뭐가 더 중요한 특징인지 인지하고 합해진다.

### 그렇다면 왜 합성곱을 여러번 할까?

- 예를 들어서 5x5 합성곱 연산을 한번 하든, 3x3 합성곱 연산을 두번 하든, receptive field도 똑같고 피처 맵의 사이즈도 동일한데 왜 굳이 VGG-Net에서 3x3을 고집했는가?
    - Receptive Field란, 다음과 같이 피처 맵의 값이 만들어지기 위해 반영된 field를 말한다.
    
    ![image 5.png](/assets/images/dl-theory/image%205.png)
    
- 이유는 3가지다.
    - Non-Linearity
        - 각 합성곱 연산이 이루어진 후 ReLU를 통과한다.
        - 비선형 활성화 함수를 여러 번 통과함으로써 비선형성이 증가.
        - 즉, 입력과 출력 간의 관계를 더욱 비선형하게 만들어줌.
    - Weight
        - 학습해야되는 파라미터의 갯수가 줄어든다.
        - 5x5는 가중치가 25개, 3x3 필터 2개는 가중치가 18개이므로 파라미터의 수가 줄어든다.
    - 중요도 (혁펜하임 피셜)
        - 다음과 같이 여러 번의 합성곱을 해주면 중요한 곳에 대한 집중도가 가장 커지고 그 이후 주변으로 퍼져나가는 식으로 반영이 된다고 한다.
        
        ![image.png](/assets/images/dl-theory/image%201%203.png)
        

### 왜 마지막에 MLP를 사용하는가?

- 최종적으로 주변의 모든 정보를 반영하여 최종 결정을 내리는 것이다.
    - 만약 특징만 인식하였을 때 고양이라고 판단했는데 주변이 물이면 어떡할 것인가?
    - 테두리 쪽에 중요한 정보도 있을 가능성이 농후

### 과도한 Max Pooling

- 풀링을 과도하게 할 시 위치 정보가 사라질 가능성이 있어 오히려 모델의 성능을 저하 시킨다.

### 3차원 데이터의 입력

- MLP처럼 열벡터로 데이터가 들어가는 것이 아니라 사진의 형태 그대로 CNN을 통과하기 때문에 입력 데이터의 위치 정보를 살리며 모델을 훈련시킬 수 있다.